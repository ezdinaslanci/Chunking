/usr/bin/python3.5 /home/ezdin/PycharmProjects/NLP_Project-1/Chunking.py

	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 1

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 1
Performance Metrics for Pos(t-1), Pos(t) with Logistic Regression Method: 
Wait for Training ...
Accuracy:  0.894157049662
             precision    recall  f1-score   support

          0       0.49      0.02      0.03      2057
          1       0.65      0.73      0.69      4227
          2       0.00      0.00      0.00        56
          3       0.67      0.13      0.22        31
          4       0.00      0.00      0.00        10
          5       0.91      0.93      0.92     55062
          6       0.81      0.90      0.85     21281
          7       0.89      0.13      0.22       556
          8       0.00      0.00      0.00      2207
          9       0.00      0.00      0.00         2
         10       0.88      0.94      0.91     21467
         11       0.37      0.08      0.14       643
         12       0.41      0.42      0.41       443
         13       0.00      0.00      0.00        73
         14       0.00      0.00      0.00         9
         15       0.93      0.92      0.92     63297
         16       0.00      0.00      0.00       291
         17       0.00      0.00      0.00         2
         18       0.00      0.00      0.00        70
         19       0.00      0.00      0.00         6
         20       0.85      0.90      0.87     12003
         21       0.93      0.95      0.94     27898

avg / total       0.88      0.89      0.88    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option:  1

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 2
Performance Metrics for Pos(t-1), Pos(t) with Decision Tree Method: 
Wait for Training ...
Accuracy:  0.900694880746
             precision    recall  f1-score   support

          0       0.55      0.27      0.37      2057
          1       0.71      0.70      0.70      4227
          2       0.00      0.00      0.00        56
          3       0.70      0.23      0.34        31
          4       0.00      0.00      0.00        10
          5       0.93      0.93      0.93     55062
          6       0.80      0.92      0.86     21281
          7       0.90      0.13      0.23       556
          8       0.00      0.00      0.00      2207
          9       0.00      0.00      0.00         2
         10       0.92      0.91      0.91     21467
         11       0.40      0.53      0.46       643
         12       0.42      0.50      0.46       443
         13       0.00      0.00      0.00        73
         14       1.00      0.22      0.36         9
         15       0.94      0.93      0.93     63297
         16       0.50      0.00      0.01       291
         17       0.00      0.00      0.00         2
         18       0.00      0.00      0.00        70
         19       0.00      0.00      0.00         6
         20       0.83      0.94      0.88     12003
         21       0.94      0.95      0.94     27898

avg / total       0.89      0.90      0.89    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 2

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 1
Performance Metrics for Pos(t-1), Pos(t), Pos(t+1) with Logistic Regression Method: 
Wait for Training ...
Accuracy:  0.916014379449
             precision    recall  f1-score   support

          0       0.69      0.47      0.56      2057
          1       0.71      0.75      0.73      4227
          2       0.00      0.00      0.00        56
          3       0.60      0.19      0.29        31
          4       0.00      0.00      0.00        10
          5       0.93      0.94      0.93     55062
          6       0.85      0.96      0.90     21281
          7       0.63      0.16      0.25       556
          8       0.68      0.24      0.36      2207
          9       0.00      0.00      0.00         2
         10       0.93      0.94      0.94     21467
         11       0.62      0.53      0.57       643
         12       0.53      0.42      0.47       443
         13       0.00      0.00      0.00        73
         14       0.00      0.00      0.00         9
         15       0.94      0.93      0.93     63297
         16       0.25      0.00      0.01       291
         17       0.00      0.00      0.00         2
         18       0.00      0.00      0.00        70
         19       0.00      0.00      0.00         6
         20       0.91      0.95      0.93     12003
         21       0.95      0.95      0.95     27898

avg / total       0.91      0.92      0.91    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 2

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 2
Performance Metrics for Pos(t-1), Pos(t), Pos(t+1) with Decision Tree Method: 
Wait for Training ...
Accuracy:  0.934602793695
             precision    recall  f1-score   support

          0       0.69      0.72      0.70      2057
          1       0.77      0.81      0.79      4227
          2       0.57      0.23      0.33        56
          3       0.78      0.68      0.72        31
          4       0.77      1.00      0.87        10
          5       0.94      0.95      0.95     55062
          6       0.88      0.96      0.92     21281
          7       0.62      0.37      0.46       556
          8       0.68      0.29      0.41      2207
          9       0.00      0.00      0.00         2
         10       0.95      0.95      0.95     21467
         11       0.63      0.63      0.63       643
         12       0.65      0.60      0.62       443
         13       1.00      0.01      0.03        73
         14       1.00      0.33      0.50         9
         15       0.95      0.95      0.95     63297
         16       0.64      0.07      0.13       291
         17       0.00      0.00      0.00         2
         18       1.00      0.01      0.03        70
         19       0.00      0.00      0.00         6
         20       0.94      0.95      0.94     12003
         21       0.97      0.95      0.96     27898

avg / total       0.93      0.93      0.93    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 3

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 1
Performance Metrics for Pos(t-2), Pos(t-1), Pos(t) with Logistic Regression Method: 
Wait for Training ...
Accuracy:  0.900137464512
             precision    recall  f1-score   support

          0       0.55      0.08      0.14      2057
          1       0.66      0.73      0.69      4227
          2       0.00      0.00      0.00        56
          3       0.62      0.16      0.26        31
          4       0.00      0.00      0.00        10
          5       0.92      0.93      0.93     55062
          6       0.81      0.91      0.86     21281
          7       0.89      0.13      0.22       556
          8       0.00      0.00      0.00      2207
          9       0.00      0.00      0.00         2
         10       0.90      0.93      0.92     21467
         11       0.55      0.40      0.47       643
         12       0.50      0.39      0.44       443
         13       0.00      0.00      0.00        73
         14       0.00      0.00      0.00         9
         15       0.94      0.92      0.93     63297
         16       0.00      0.00      0.00       291
         17       0.00      0.00      0.00         2
         18       0.00      0.00      0.00        70
         19       0.00      0.00      0.00         6
         20       0.85      0.92      0.88     12003
         21       0.93      0.95      0.94     27898

avg / total       0.89      0.90      0.89    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 3

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 2
Performance Metrics for Pos(t-2), Pos(t-1), Pos(t) with Decision Tree Method: 
Wait for Training ...
Accuracy:  0.919859606691
             precision    recall  f1-score   support

          0       0.59      0.45      0.51      2057
          1       0.73      0.74      0.73      4227
          2       0.67      0.07      0.13        56
          3       0.67      0.45      0.54        31
          4       1.00      0.20      0.33        10
          5       0.95      0.95      0.95     55062
          6       0.82      0.93      0.87     21281
          7       0.96      0.14      0.25       556
          8       0.63      0.07      0.12      2207
          9       0.00      0.00      0.00         2
         10       0.93      0.94      0.93     21467
         11       0.59      0.64      0.61       643
         12       0.61      0.56      0.58       443
         13       0.57      0.18      0.27        73
         14       0.80      0.44      0.57         9
         15       0.96      0.95      0.95     63297
         16       0.56      0.31      0.40       291
         17       0.00      0.00      0.00         2
         18       0.00      0.00      0.00        70
         19       0.00      0.00      0.00         6
         20       0.88      0.95      0.91     12003
         21       0.95      0.95      0.95     27898

avg / total       0.92      0.92      0.91    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 4

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 1
Performance Metrics for Pos(t-2), Pos(t-1), Pos(t), Pos(t+1) with Logistic Regression Method: 
Wait for Training ...
Accuracy:  0.919108511935
             precision    recall  f1-score   support

          0       0.71      0.50      0.59      2057
          1       0.72      0.75      0.73      4227
          2       0.00      0.00      0.00        56
          3       0.64      0.23      0.33        31
          4       0.00      0.00      0.00        10
          5       0.93      0.94      0.93     55062
          6       0.86      0.96      0.91     21281
          7       0.61      0.17      0.27       556
          8       0.67      0.24      0.36      2207
          9       0.00      0.00      0.00         2
         10       0.93      0.94      0.94     21467
         11       0.61      0.49      0.54       643
         12       0.61      0.45      0.51       443
         13       0.52      0.15      0.23        73
         14       0.00      0.00      0.00         9
         15       0.94      0.93      0.94     63297
         16       0.36      0.01      0.03       291
         17       0.00      0.00      0.00         2
         18       0.00      0.00      0.00        70
         19       0.00      0.00      0.00         6
         20       0.92      0.95      0.93     12003
         21       0.95      0.95      0.95     27898

avg / total       0.92      0.92      0.92    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 4

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 2
Performance Metrics for Pos(t-2), Pos(t-1), Pos(t), Pos(t+1) with Decision Tree Method: 
Wait for Training ...
Accuracy:  0.956512086012
             precision    recall  f1-score   support

          0       0.78      0.84      0.81      2057
          1       0.84      0.89      0.86      4227
          2       0.76      0.52      0.62        56
          3       0.86      0.81      0.83        31
          4       0.83      1.00      0.91        10
          5       0.97      0.97      0.97     55062
          6       0.90      0.97      0.94     21281
          7       0.74      0.49      0.59       556
          8       0.83      0.38      0.52      2207
          9       0.00      0.00      0.00         2
         10       0.97      0.97      0.97     21467
         11       0.81      0.77      0.79       643
         12       0.88      0.79      0.83       443
         13       0.70      0.38      0.50        73
         14       1.00      0.67      0.80         9
         15       0.97      0.97      0.97     63297
         16       0.85      0.44      0.58       291
         17       1.00      0.50      0.67         2
         18       0.81      0.30      0.44        70
         19       0.00      0.00      0.00         6
         20       0.96      0.97      0.97     12003
         21       0.98      0.96      0.97     27898

avg / total       0.96      0.96      0.96    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 5

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 1
Performance Metrics for Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2) with Logistic Regression Method: 
Wait for Training ...
Accuracy:  0.921616884988
             precision    recall  f1-score   support

          0       0.72      0.54      0.62      2057
          1       0.73      0.75      0.74      4227
          2       0.00      0.00      0.00        56
          3       0.64      0.23      0.33        31
          4       0.00      0.00      0.00        10
          5       0.93      0.94      0.94     55062
          6       0.87      0.96      0.91     21281
          7       0.60      0.19      0.29       556
          8       0.75      0.31      0.44      2207
          9       0.00      0.00      0.00         2
         10       0.93      0.95      0.94     21467
         11       0.64      0.48      0.55       643
         12       0.60      0.46      0.52       443
         13       0.50      0.08      0.14        73
         14       0.00      0.00      0.00         9
         15       0.94      0.93      0.94     63297
         16       0.38      0.02      0.03       291
         17       0.00      0.00      0.00         2
         18       0.00      0.00      0.00        70
         19       0.00      0.00      0.00         6
         20       0.92      0.95      0.93     12003
         21       0.95      0.95      0.95     27898

avg / total       0.92      0.92      0.92    211691


	1. Pos(t-1), Pos(t)
	2. Pos(t-1), Pos(t), Pos(t+1)
	3. Pos(t-2), Pos(t-1), Pos(t)
	4. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1)
	5. Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2)
Enter Your Feature Option: 5

	1. Logistic Regression
	2. Decison Tree
Enter Your Method Option: 2
Performance Metrics for Pos(t-2), Pos(t-1), Pos(t), Pos(t+1), Pos(t+2) with Decision Tree Method: 
Wait for Training ...
Accuracy:  0.976352324851
             precision    recall  f1-score   support

          0       0.89      0.95      0.92      2057
          1       0.91      0.96      0.94      4227
          2       0.84      0.73      0.78        56
          3       0.97      0.94      0.95        31
          4       1.00      1.00      1.00        10
          5       0.98      0.99      0.98     55062
          6       0.94      0.98      0.96     21281
          7       0.91      0.67      0.77       556
          8       0.94      0.61      0.74      2207
          9       0.67      1.00      0.80         2
         10       0.99      0.98      0.98     21467
         11       0.92      0.89      0.91       643
         12       0.96      0.89      0.93       443
         13       0.82      0.77      0.79        73
         14       0.90      1.00      0.95         9
         15       0.98      0.98      0.98     63297
         16       0.88      0.73      0.80       291
         17       1.00      1.00      1.00         2
         18       0.95      0.59      0.73        70
         19       1.00      0.17      0.29         6
         20       0.98      0.98      0.98     12003
         21       0.99      0.98      0.98     27898

avg / total       0.98      0.98      0.98    211691

